{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import datasets, transforms , models\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"Data/train\"\n",
    "test_folder = \"Data/test1\"\n",
    "\n",
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  25000\n",
      "Number of test images:  12500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training images: \", len(train_list))\n",
    "print(\"Number of test images: \", len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = os.path.join(train_folder, train_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([\n",
    "    transforms.Resize((60,60)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data_folder, data_list, transform = None):\n",
    "        self.data_folder = data_folder\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "            return int(len(self.data_list))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "         imgpath = os.path.join(self.data_folder, self.data_list[idx])\n",
    "         img = Image.open(imgpath)\n",
    "         if 'cat' in imgpath:\n",
    "             label = 0\n",
    "         else:\n",
    "             label = 1\n",
    "         if self.transform is not None:\n",
    "             img = self.transform(img)\n",
    "         return(img, label)    \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset(train_folder, train_list, transformation)\n",
    "test = Dataset(test_folder, test_list, transformation)\n",
    "\n",
    "train, val = torch.utils.data.random_split(train, [20000, 5000])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = 64, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size = 64, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "\n",
    "\n",
    "class ImageTransferLearning(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        backbone = models.resnet50(pretrained = True)\n",
    "        num_features = backbone.fc.in_features    #capturing the number of features in the last layer of the backbone in this case resnet50 the last layer is a linear layer with 2048 features\n",
    "        layers = list(backbone.children())[:-1]   # capturing all the layers of the backbone except the last layer that means all convolutional layers\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*layers)  # creating a sequential model with all the layers of the backbone except the last layer\n",
    "        num_target_classes = 2\n",
    "        self.classifier = nn.Linear(num_features, num_target_classes)           # creating a linear layer with 2048 input features and 2 output features\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "            self.feature_extractor.eval()              # setting the feature extractor to evaluation mode that means the weights of the feature extractor will not be updated\n",
    "            with torch.no_grad():\n",
    "                representations = self.feature_extractor(x).flatten(1)          # that is a representation of the input image that is passed through the feature extractor that is frozen layer and not updated\n",
    "            x = self.classifier(representations)                # passing the output of the feature extractor through the our classifier that make 2048 input features to 2 output features\n",
    "            return F.softmax(x, dim =1)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "            return torch.utils.data.DataLoader(train, batch_size = 64, shuffle = True)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "            return torch.utils.data.DataLoader(val, batch_size = 64, shuffle = True)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "            data, label = batch\n",
    "            output = self.forward(data)\n",
    "            loss = self.cross_entropy_loss(output, label)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            self.log('train_loss', loss)\n",
    "            self.log('train_acc', self.accuracy(preds, label))\n",
    "            return {'loss': loss, 'lof': loss}\n",
    "        \n",
    "    def on_train_epoch_end(self):\n",
    "            self.log('train_acc_epoc' , self.accuracy.compute()) \n",
    "        \n",
    "    def validation_step(self, batch , batch_idx):\n",
    "            val_data, val_label = batch\n",
    "            output = self.forward(val_data)\n",
    "            loss = self.cross_entropy_loss(output, val_label)\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            self.log('val_loss', loss)\n",
    "            self.log('val_acc', self.accuracy(preds, val_label))\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "            self.log('val_acc_epoc' , self.accuracy.compute())    \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "            return F.nll_loss(logits,labels)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "            optimizer = optim.Adam(self.parameters(), lr = 0.001)\n",
    "            return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type           | Params\n",
      "-----------------------------------------------------\n",
      "0 | accuracy          | BinaryAccuracy | 0     \n",
      "1 | feature_extractor | Sequential     | 23.5 M\n",
      "2 | classifier        | Linear         | 4.1 K \n",
      "-----------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.004507780075073242,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536a7faa74694288bf2de1d76814e827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029997825622558594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bbd6bcd6c7460f8eb31f7a5d20405a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029954910278320312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f25dea4f37a4889bf01a571e85cb3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0035114288330078125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9599f67f9bc45629b269261e9ac9471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "model =ImageTransferLearning()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    max_epochs=10)\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
